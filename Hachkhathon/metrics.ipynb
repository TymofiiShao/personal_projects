{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b84eb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('models1.pkl', 'rb') as f:\n",
    "  models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50aff278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.metrics import mean_absolute_percentage_error as mape\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d1f0582",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.npy', 'rb') as f:\n",
    "    X_test = np.load(f)\n",
    "    y_test = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97fa5cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test R2_score =  0.7638522762409652\n",
      "test rmse_score =  1.072284493316548\n",
      "test mape_score =  99494980624846.48\n",
      "test mae_score =  0.13278890084457187\n",
      "(mape для y!=0): 22.86196157083573\n"
     ]
    }
   ],
   "source": [
    "# linear regression\n",
    "print('test R2_score = ', models[0].score(X_test, y_test))\n",
    "print('test rmse_score = ', np.sqrt(mse(y_test, models[0].predict(X_test))))\n",
    "print('test mape_score = ', mape(y_test, models[0].predict(X_test)))\n",
    "print('test mae_score = ', mae(y_test, models[0].predict(X_test)))\n",
    "print('(mape для y!=0):',mape(y_test[y_test!=0], models[0].predict(X_test)[y_test!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "734ed18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test R2_score =  0.7844315226453266\n",
      "test rmse_score =  1.0244971881004095\n",
      "test mape_score =  28819444574364.25\n",
      "test mae_score =  0.09425775305817256\n",
      "(mape для y!=0): 7.521882858943411\n"
     ]
    }
   ],
   "source": [
    "# MLP regressor\n",
    "print('test R2_score = ', models[1].score(X_test, y_test))\n",
    "print('test rmse_score = ', np.sqrt(mse(y_test, models[1].predict(X_test))))\n",
    "print('test mape_score = ', mape(y_test, models[1].predict(X_test)))\n",
    "print('test mae_score = ', mae(y_test, models[1].predict(X_test)))\n",
    "print('(mape для y!=0):',mape(y_test[y_test!=0], models[1].predict(X_test)[y_test!=0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c73d178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test R2_score =  0.7825550247756997\n",
      "test rmse_score =  1.0289465890850418\n",
      "test mape_score =  30619358834314.445\n",
      "test mae_score =  0.0895138132817083\n",
      "(mape для y!=0): 5.21730293656799\n"
     ]
    }
   ],
   "source": [
    "# GradientBoostingRegressor\n",
    "print('test R2_score = ', models[2].score(X_test, y_test))\n",
    "print('test rmse_score = ', np.sqrt(mse(y_test, models[2].predict(X_test))))\n",
    "print('test mape_score = ', mape(y_test, models[2].predict(X_test)))\n",
    "print('test mae_score = ', mae(y_test, models[2].predict(X_test)))\n",
    "print('(mape для y!=0):',mape(y_test[y_test!=0], models[2].predict(X_test)[y_test!=0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d0f20c",
   "metadata": {},
   "source": [
    "   За основну метрику виберемо MAE, так як вона найбільш чітко відображає реальне відхилення моделі, a MAPE не підходить для цих даних, тому що у вибірці занадто багато нульових значень і не можна виміряти якість прогнозів відносно абсолютних значень, замість неї можна використати метрику - коефіцієнт детермінації (якість прогнозів відносно дисперсії). Проведемо аналіз отриманих результатів. Досягнена точність 0.78 на тестовій вибірці. Це можна назвати гарним, за деякими канонами реалістичним результатом.\n",
    "   \n",
    "   Метрики:\n",
    "        Корінь середньої квадратичної похибки трохи більше одиниці. Ця метрика трохи збільшує значимість малих похибок, тож ми не будемо її використовувати\n",
    "        MAE середня сума абсолютної різниці між вірним і передбаченим показує хороші результати. Це говорить про те, що похибка у передбачених значеннях є невисокою. Рахуючи що ми працюємо з передбаченням реальних доходів, то ми вважаємо це хорошим результатом, тож обираємо саме цю метрику.\n",
    "   \n",
    "   Таким чином ми можемо спрогнозувати загальну картину наших потенційних доходів, що хоч і не буде 100% точною, але в загальному відображатиме, що нас очікує\n",
    "   \n",
    "   Серед трьох розглянутих моделей найбільш оптимальною, на думку команди є модель з використанням алгоритму GradientBoostingRegressor. Оскільки модель з лінійною регресією та MLP регресію мають менш задовільні показники MAE у порівнянні з обраною моделю.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb1b1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
